{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM1LYFR8dtkkRREs/5b0kyT"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9754425,"sourceType":"datasetVersion","datasetId":5972470},{"sourceId":9834007,"sourceType":"datasetVersion","datasetId":6031879}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classifying Diaster Related Tweets as Real or Fake\nContinuation of the Project. Building the Classification Model using a Transformer","metadata":{"id":"xNNiwDgLZPFU"}},{"cell_type":"code","source":"# Libaries\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"y3eGw0mwbca1","executionInfo":{"status":"ok","timestamp":1730204320713,"user_tz":-60,"elapsed":16994,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"execution":{"iopub.status.busy":"2024-11-07T13:25:30.441382Z","iopub.execute_input":"2024-11-07T13:25:30.441699Z","iopub.status.idle":"2024-11-07T13:25:34.297061Z","shell.execute_reply.started":"2024-11-07T13:25:30.441655Z","shell.execute_reply":"2024-11-07T13:25:34.296220Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/text-classification/train.csv')\ntrain_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"60ekKEEqgIFm","executionInfo":{"status":"ok","timestamp":1730204321624,"user_tz":-60,"elapsed":490,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"outputId":"09c3a8e6-ac69-44c7-d514-d25527935e89","execution":{"iopub.status.busy":"2024-11-07T13:25:34.298182Z","iopub.execute_input":"2024-11-07T13:25:34.298687Z","iopub.status.idle":"2024-11-07T13:25:34.351710Z","shell.execute_reply.started":"2024-11-07T13:25:34.298651Z","shell.execute_reply":"2024-11-07T13:25:34.350840Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmkMsQe1gYpx","executionInfo":{"status":"ok","timestamp":1730204321624,"user_tz":-60,"elapsed":42,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"outputId":"7a73fbb4-3624-443d-e9bc-e5beedfdc325","execution":{"iopub.status.busy":"2024-11-07T13:25:34.352934Z","iopub.execute_input":"2024-11-07T13:25:34.353909Z","iopub.status.idle":"2024-11-07T13:25:34.359675Z","shell.execute_reply.started":"2024-11-07T13:25:34.353873Z","shell.execute_reply":"2024-11-07T13:25:34.358702Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(7613, 5)"},"metadata":{}}]},{"cell_type":"code","source":"train_df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMPmZoDagfUX","executionInfo":{"status":"ok","timestamp":1730204321624,"user_tz":-60,"elapsed":38,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"outputId":"dfe8a4d9-3188-452f-c5c8-b85657c50fc0","execution":{"iopub.status.busy":"2024-11-07T13:25:34.363295Z","iopub.execute_input":"2024-11-07T13:25:34.363607Z","iopub.status.idle":"2024-11-07T13:25:34.377099Z","shell.execute_reply.started":"2024-11-07T13:25:34.363577Z","shell.execute_reply":"2024-11-07T13:25:34.376107Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        7613 non-null   int64 \n 1   keyword   7552 non-null   object\n 2   location  5080 non-null   object\n 3   text      7613 non-null   object\n 4   target    7613 non-null   int64 \ndtypes: int64(2), object(3)\nmemory usage: 297.5+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"# dropping the variables that are not useful for our modeling\n\ntrain_df.drop(['id', 'location', 'keyword'], axis=1, inplace=True)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T13:25:34.378283Z","iopub.execute_input":"2024-11-07T13:25:34.378562Z","iopub.status.idle":"2024-11-07T13:25:34.391151Z","shell.execute_reply.started":"2024-11-07T13:25:34.378531Z","shell.execute_reply":"2024-11-07T13:25:34.390099Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text  target\n0  Our Deeds are the Reason of this #earthquake M...       1\n1             Forest fire near La Ronge Sask. Canada       1\n2  All residents asked to 'shelter in place' are ...       1\n3  13,000 people receive #wildfires evacuation or...       1\n4  Just got sent this photo from Ruby #Alaska as ...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Build a Transformer Model","metadata":{"id":"xVAnvXvd6Ofo"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train_df[\"text\"]\ny = train_df[\"target\"]\n\n# split the data into training (80%) and validation sets (20%)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 100)\nprint(F\"X_train: {X_train.shape}, X_val: {X_val.shape}, y_train: {y_train.shape}, y_val: {y_val.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWf3dUyRDR7D","executionInfo":{"status":"ok","timestamp":1730204332621,"user_tz":-60,"elapsed":20,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"outputId":"0ec77595-fc25-4212-a417-44e802f517f3","execution":{"iopub.status.busy":"2024-11-07T13:25:34.392298Z","iopub.execute_input":"2024-11-07T13:25:34.392680Z","iopub.status.idle":"2024-11-07T13:25:34.460669Z","shell.execute_reply.started":"2024-11-07T13:25:34.392619Z","shell.execute_reply":"2024-11-07T13:25:34.459784Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"X_train: (6090,), X_val: (1523,), y_train: (6090,), y_val: (1523,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom transformers import AutoTokenizer\n","metadata":{"id":"l8kyGFxbLPV9","executionInfo":{"status":"ok","timestamp":1730204414944,"user_tz":-60,"elapsed":8,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-11-07T13:25:34.461851Z","iopub.execute_input":"2024-11-07T13:25:34.462248Z","iopub.status.idle":"2024-11-07T13:25:37.048061Z","shell.execute_reply.started":"2024-11-07T13:25:34.462201Z","shell.execute_reply":"2024-11-07T13:25:37.047054Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\nprint(f\"Tokenizer Model Maximum Length: {tokenizer.model_max_length}\")\nprint(f\"Tokenizer Model Vocabulary Size: {tokenizer.vocab_size}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfiZCHK-BxrR","executionInfo":{"status":"ok","timestamp":1730204416893,"user_tz":-60,"elapsed":1955,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"outputId":"e61c7876-67ea-4b74-ce19-c753fdb0a9ac","execution":{"iopub.status.busy":"2024-11-07T13:25:37.049383Z","iopub.execute_input":"2024-11-07T13:25:37.049984Z","iopub.status.idle":"2024-11-07T13:25:37.477386Z","shell.execute_reply.started":"2024-11-07T13:25:37.049947Z","shell.execute_reply":"2024-11-07T13:25:37.476484Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Tokenizer Model Maximum Length: 512\nTokenizer Model Vocabulary Size: 30522\n","output_type":"stream"}]},{"cell_type":"code","source":"train_encoding = tokenizer(list(X_train), truncation=True, padding=True)\nval_encoding = tokenizer(list(X_val), truncation=True, padding=True)","metadata":{"id":"YporKBHw3Bib","executionInfo":{"status":"ok","timestamp":1730204418003,"user_tz":-60,"elapsed":1113,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"execution":{"iopub.status.busy":"2024-11-07T13:25:37.478421Z","iopub.execute_input":"2024-11-07T13:25:37.478720Z","iopub.status.idle":"2024-11-07T13:25:37.950840Z","shell.execute_reply.started":"2024-11-07T13:25:37.478689Z","shell.execute_reply":"2024-11-07T13:25:37.950008Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Transforming to tensorflow datasets\n# Preparing the data for transformer\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encoding), tf.constant(y_train.values, dtype=tf.int32)))\n\nval_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encoding), tf.constant(y_val.values, dtype=tf.int32)))\n\n\n# configuring the datasets\n\ntrain_dataset = train_dataset.shuffle(len(X_train)).batch(16)\n\nval_dataset = val_dataset.batch(16)","metadata":{"id":"RpFKFA86ELJE","executionInfo":{"status":"ok","timestamp":1730204420793,"user_tz":-60,"elapsed":2793,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"execution":{"iopub.status.busy":"2024-11-07T13:25:37.952724Z","iopub.execute_input":"2024-11-07T13:25:37.953120Z","iopub.status.idle":"2024-11-07T13:25:42.236489Z","shell.execute_reply.started":"2024-11-07T13:25:37.953076Z","shell.execute_reply":"2024-11-07T13:25:42.235557Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Build the model\n\nmodel = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 2)\n\n# Define optimizer, loss, and metrics \noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n\n# Compile the model \nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n# Fit the model\nmodel.fit(train_dataset, epochs=10, verbose = False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"UdNAQOkhGmnr","executionInfo":{"status":"error","timestamp":1730204905977,"user_tz":-60,"elapsed":3498,"user":{"displayName":"Oseni Qudus","userId":"18321526593163139399"}},"outputId":"fddf9b63-83a9-4b5e-a357-edd94c1aaabe","execution":{"iopub.status.busy":"2024-11-07T13:25:42.238100Z","iopub.execute_input":"2024-11-07T13:25:42.238509Z","iopub.status.idle":"2024-11-07T13:35:31.096392Z","shell.execute_reply.started":"2024-11-07T13:25:42.238464Z","shell.execute_reply":"2024-11-07T13:35:31.095416Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"WARNING: AutoGraph could not transform <function infer_framework at 0x7a93011abd90> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730985990.347155    2422 service.cc:145] XLA service 0x7a8ed4e9f6d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730985990.347206    2422 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730985990.347211    2422 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730985990.440735    2422 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7a92c82100a0>"},"metadata":{}}]},{"cell_type":"code","source":"# Model Evaluation\n\ntrain_loss, train_acc = model.evaluate(train_dataset)\nprint(F\"Train set accuracy: {train_acc}\")\n\nval_loss, val_acc = model.evaluate(val_dataset)\nprint(F\"Validation set accuracy: {val_acc}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T13:35:31.097875Z","iopub.execute_input":"2024-11-07T13:35:31.098193Z","iopub.status.idle":"2024-11-07T13:36:05.504526Z","shell.execute_reply.started":"2024-11-07T13:35:31.098158Z","shell.execute_reply":"2024-11-07T13:36:05.503696Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"381/381 [==============================] - 25s 50ms/step - loss: 0.0248 - accuracy: 0.9878\nTrain set accuracy: 0.9878489375114441\n96/96 [==============================] - 9s 47ms/step - loss: 0.8444 - accuracy: 0.8240\nValidation set accuracy: 0.8240315318107605\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Conclusion\nIn this project,built a deep learning classification model using Tensorflow. I used a real world tweets dataset to predict whether a tweet indicated disaster or not.\n\nFrom the previous notebook of the same project. I started with a shallow neural network and went all the way to build Transformer based models. The performance of these various models are summarized below;\n\n+ **`Shallow Neural Network`**: Training set and Validation set accuracy are 58%\n+ **`Multilayer Deep Text Classification Model`**: Training set accuracy 56% and Validation set accuracy of 57%\n+ **`Multilayer Bidirectional LSTM Model`**: Training set 95% and Validation set accuracy of 78% \n+ **`Transformer Model`**: Training set accuracy 98% and Validation set accuracy of 82%\n\nThe best performance comes from Transformer Model.\n","metadata":{}}]}